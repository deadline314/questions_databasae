[
  {
    "question": "Zep相較於MemGPT在深度記憶檢索(DMR)基準測試中的表現如何？",
    "answer": "Zep的表現優於MemGPT，在DMR中達到94.8%的準確率，而MemGPT為93.4%。",
    "filename": "Zep"
  },
  {
    "question": "Zep的核心組件是什麼？",
    "answer": "Graphiti，一個具時間意識的知識圖引擎。",
    "filename": "Zep"
  },
  {
    "question": "Zep在什麼基準測試中驗證了它的能力超越DMR？",
    "answer": "LongMemEval基準測試。",
    "filename": "Zep"
  },
  {
    "question": "Zep在LongMemEval基準測試中的性能提升是多少？",
    "answer": "準確率提升高達18.5%。",
    "filename": "Zep"
  },
  {
    "question": "Zep通過哪種方法解決現有RAG框架的基本限制？",
    "answer": "動態整合未結構化對話數據和結構化商業數據，同時維護歷史關係。",
    "filename": "Zep"
  },
  {
    "question": "Zep是怎樣的系統？",
    "answer": "一個針對AI代理的記憶層服務。",
    "filename": "Zep"
  },
  {
    "question": "在Zep架構中，知識圖由哪三個分層子圖構成？",
    "answer": "情節子圖、語義實體子圖和社區子圖。",
    "filename": "Zep"
  },
  {
    "question": "什麼是情節子圖的主要作用？",
    "answer": "作為數據存儲，從中提取語義實體和關係。",
    "filename": "Zep"
  },
  {
    "question": "為什麼Zep的雙重存儲設計很重要？",
    "answer": "反映心理學中對人類記憶的建模，區分情節記憶和語義記憶。",
    "filename": "Zep"
  },
  {
    "question": "Zep如何處理實體提取的過程？",
    "answer": "對當前訊息內容及過去4條訊息進行處理，以提供命名實體識別的上下文。",
    "filename": "Zep"
  },
  {
    "question": "什麼是Graphiti的關鍵特徵之一，以區別於其他知識圖引擎？",
    "answer": "管理動態信息更新的時間提取和邊無效化過程。",
    "filename": "Zep"
  },
  {
    "question": "Zep的社區子圖通過什麼算法構建？",
    "answer": "標籤傳播算法。",
    "filename": "Zep"
  },
  {
    "question": "在Zep中，如何表達新數據進入圖時的社區更新？",
    "answer": "動態擴展標籤傳播的一個遞歸步驟。",
    "filename": "Zep"
  },
  {
    "question": "Zep的記憶檢索系統主要實現哪些功能？",
    "answer": "強大、複雜且高度可配置的功能。",
    "filename": "Zep"
  },
  {
    "question": "Zep使用的三個主要搜尋方法是什麼？",
    "answer": "餘弦語義相似性搜尋、Okapi BM25全文搜尋、廣度優先搜尋。",
    "filename": "Zep"
  },
  {
    "question": "Zep中再排序器的作用是什麼？",
    "answer": "通過優先顯示最相關的結果提高精確性。",
    "filename": "Zep"
  },
  {
    "question": "在進行對話記憶集成實驗中，Zep最常用哪個模型？",
    "answer": "gpt-4o-mini模型。",
    "filename": "Zep"
  },
  {
    "question": "LongMemEval數據集中對話的平均長度是多少？",
    "answer": "平均115,000個token。",
    "filename": "Zep"
  },
  {
    "question": "Zep在DMR測試中使用gpt-4o-mini的準確性是多少？",
    "answer": "98.2%。",
    "filename": "Zep"
  },
  {
    "question": "在LongMemEval測試中，使用gpt-4o-mini的Zep相較於基線準確率提高了多少？",
    "answer": "提高了15.2%。",
    "filename": "Zep"
  },
  {
    "question": "Zep如何在知識圖中整合時間的信息？",
    "answer": "使用bi-temporal模型，追蹤事實的四個時間戳。",
    "filename": "Zep"
  },
  {
    "question": "在進行記憶檢索時，Zep的輸出由哪些要素組成？",
    "answer": "語義邊、實體單元和社區單元。",
    "filename": "Zep"
  },
  {
    "question": "Zep的再排序器支持哪兩種現有的方法？",
    "answer": "互惠排名融合(RRF)和最大邊緣差異(MMR)。",
    "filename": "Zep"
  },
  {
    "question": "Zep能夠管理多少種類型的問題？",
    "answer": "六種類型的問題。",
    "filename": "Zep"
  },
  {
    "question": "Zep的社區檢索策略與LightRAG的方法有何相似之處？",
    "answer": "都採用高級關鍵檢索方法。",
    "filename": "Zep"
  },
  {
    "question": "在LongMemEval中的哪種類型問題上Zep的增益面最為顯著？",
    "answer": "單回合偏好、多回合和時間推理問題類型。",
    "filename": "Zep"
  },
  {
    "question": "在Zep架構中，事實提取的關鍵目的是什麼？",
    "answer": "建立明確的兩個不同實體節點之間的關係。",
    "filename": "Zep"
  },
  {
    "question": "Zep的資訊檢索過程中有哪三個明確步驟？",
    "answer": "搜尋、再排序、建構。",
    "filename": "Zep"
  },
  {
    "question": "Zep在DMR測試中使用哪個模型達到94.8%的準確率？",
    "answer": "gpt-4-turbo。",
    "filename": "Zep"
  },
  {
    "question": "什麼可作為Zep中節點距離再排序器的基準？",
    "answer": "指定的中心節點。",
    "filename": "Zep"
  },
  {
    "question": "Zep以什麼形式處理事實提取的時間信息？",
    "answer": "使用有效區間的日期範圍表示。",
    "filename": "Zep"
  },
  {
    "question": "什麼是Zep在DMR數據集上的一大限制？",
    "answer": "數據集規模小且不足以代表真實企業應用場景。",
    "filename": "Zep"
  },
  {
    "question": "在Zep的知識圖中，邊的無效化過程是如何進行的？",
    "answer": "當識別到時間重疊的矛盾時，將受影響的邊設為無效。",
    "filename": "Zep"
  },
  {
    "question": "Graphiti引擎用於表達什麼類型的世界觀？",
    "answer": "複雜、動態演變的世界觀。",
    "filename": "Zep"
  },
  {
    "question": "在Zep圖構建中，如何表達社區節點中的高層次結構和領域概念？",
    "answer": "使用社區節點來總結和連接實體成員。",
    "filename": "Zep"
  },
  {
    "question": "Zep在企業應用中最突出的任務有哪些？",
    "answer": "跨會話信息綜合和長期上下文維護。",
    "filename": "Zep"
  },
  {
    "question": "Zep在DMR中使用什麼方法提高準確性？",
    "answer": "使用高效的search和reranking技術獲取最相關的節點與邊。",
    "filename": "Zep"
  },
  {
    "question": "Zep的再排序器還使用了什麼樣的技術來優化性能？",
    "answer": "使用cross-encoders生成相關性評分。",
    "filename": "Zep"
  },
  {
    "question": "Zep如何使用計時符號來管理知識圖中的時間信息？",
    "answer": "使用有效和無效日期字段來管理事實的時間跨度。",
    "filename": "Zep"
  },
  {
    "question": "Zep的性能表現在於何種提升？",
    "answer": "準確性和延遲的顯著改善，特別是在複雜和細緻的問題類型上。",
    "filename": "Zep"
  },
  {
    "question": "Zep如何幫助提高用於檢索的上下文窗口效率？",
    "answer": "通過動態集成連續交互數據創建和管理大型數據庫。",
    "filename": "Zep"
  },
  {
    "question": "在使用知識圖時，Zep如何處理實體名稱的重複問題？",
    "answer": "通過餘弦相似性搜尋和實體解析提示回應。",
    "filename": "Zep"
  },
  {
    "question": "Zep的知識圖採取什麼樣的構造層級？",
    "answer": "從情節到事實到實體再到社區。",
    "filename": "Zep"
  },
  {
    "question": "Zep如何在知識圖的廣度優先搜尋中改善初始搜尋結果？",
    "answer": "識別n跳內的附加節點和邊。",
    "filename": "Zep"
  },
  {
    "question": "Zep的實驗實施選擇使用哪種嵌入模型？",
    "answer": "BGE-m3模型。",
    "filename": "Zep"
  },
  {
    "question": "在實驗中，使用gpt-4-turbo的Zep對整體對話記憶的準確率是多少？",
    "answer": "94.4%",
    "filename": "Zep"
  },
  {
    "question": "在實驗中，Zep使用的gpt-4o-mini模型達到了什麼準確率？",
    "answer": "使用gpt-4o-mini的Zep達到了98.2%準確率。",
    "filename": "Zep"
  },
  {
    "question": "Zep中使用的是哪種時態搜尋方法？",
    "answer": "bi-temporal模型，用以追蹤事實的四個時間戳。",
    "filename": "Zep"
  },
  {
    "question": "Spark-TTS使用什麼方法來提升文本轉語音合成的效率？",
    "answer": "使用單一流編碼器BiCodec來分解語音為語義與全局語音碼元，提升效率。",
    "filename": "Spark_TTS"
  },
  {
    "question": "BiCodec如何實現語音的可控性？",
    "answer": "透過結合低位率語義碼元與固定長度全局碼元，實現可控性。",
    "filename": "Spark_TTS"
  },
  {
    "question": "什麼是VoxBox？",
    "answer": "VoxBox是一個精心策劃的10萬小時語料庫，包含完善的屬性標註。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS的語音合成系統有何創新？",
    "answer": "系統能在不參考參考音頻的情況下，通過屬性控制創建新的說話者語音。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS的整合性架構如何影響其性能？",
    "answer": "其單一編碼器架構與傳統文本LLM對齊，支持靈活的語音創建。",
    "filename": "Spark_TTS"
  },
  {
    "question": "何為語音代碼化技術在TTS系統中的貢獻？",
    "answer": "語音代碼化技術提高了語音合成的自然度，使合成語音幾乎與人聲無異。",
    "filename": "Spark_TTS"
  },
  {
    "question": "什麼是BiCodec的兩種碼元類型？",
    "answer": "低位率語義碼元與固定長度全局碼元。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS如何在語音合成中實現細粒度調節？",
    "answer": "實現精確音高值和講話速率等細粒度的調節。",
    "filename": "Spark_TTS"
  },
  {
    "question": "零樣本TTS涉及哪兩種類型的代碼預測模型？",
    "answer": "首先是單流代碼預測，其次是多流代碼預測。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS和Llasa使用的主要架構有何不同？",
    "answer": "Llasa使用的是8B參數和250k小時的數據，而Spark-TTS只有0.5B參數和100k小時數據。",
    "filename": "Spark_TTS"
  },
  {
    "question": "BiCodec的模型結構中包含哪些部分？",
    "answer": "語義編碼器、全局編碼器和解碼器。",
    "filename": "Spark_TTS"
  },
  {
    "question": "VoxBox數據集的幾個主要特徵是什麼？",
    "answer": "包含35種不同語言的說話人數據和多種語音屬性標註。",
    "filename": "Spark_TTS"
  },
  {
    "question": "MLMS（大語言模型中使用）在語音合成上有什麼作用？",
    "answer": "MLMS用於語音屬性的語言模型編碼，如性別、音高和速率。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS的架構如何簡化了文本LLM到語音的生成流程？",
    "answer": "BiCodec直接處理LM的輸出以生成語音波形，簡化流程。",
    "filename": "Spark_TTS"
  },
  {
    "question": "VoxBox在研究可控的TTS中有什麼作用？",
    "answer": "VoxBox提供了一個開源數據資源基礎，用來建立可復現的基準。",
    "filename": "Spark_TTS"
  },
  {
    "question": "什麼是BiCodec的量化技術採用的方法？",
    "answer": "使用單碼書向量量化來進行量化，並使用FSQ代替VQ。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS如何通過CoT來預測語音屬性？",
    "answer": "透過包含屬性標籤的輸入，在CoT模式下預測細粒度屬性值。",
    "filename": "Spark_TTS"
  },
  {
    "question": "什麼是Spark-TTS中使用的語言模型的名稱？",
    "answer": "Qwen2.5-0.5B。",
    "filename": "Spark_TTS"
  },
  {
    "question": "BiCodec在語音合成中的音質評分主要由什麼量表來評估？",
    "answer": "由PESQ和UTMOS指標進行評估。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS在什麼指標上展示了更高的性能？",
    "answer": "在語音的聲學自然度和整體語質上表現出色。",
    "filename": "Spark_TTS"
  },
  {
    "question": "BiCodec的編解碼框架採用什麼模型結構？",
    "answer": "採用標準的VQ-VAE編解碼框架。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS相較於傳統TTS方法的優勢是什麼？",
    "answer": "實現自治編碼器架構，支持靈活語音生成，提升合成效率。",
    "filename": "Spark_TTS"
  },
  {
    "question": "如何評估BiCodec在語音代碼重建中的性能？",
    "answer": "使用STOI、PESQ和SIM等度量來評估。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS使用什麼方法達到了高效的零樣本語音合成？",
    "answer": "使用單一流代碼與屬性標籤整合預測技術。",
    "filename": "Spark_TTS"
  },
  {
    "question": "如何在Spark-TTS中針對講話速率進行控制？",
    "answer": "透過屬性標籤和精細值實現，系統支持兩種控制層次。",
    "filename": "Spark_TTS"
  },
  {
    "question": "如何利用Spark-TTS創建新的說話者語音？",
    "answer": "通過屬性控制系統創建不需參考音頻的新說話者語音。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS的主要貢獻有哪些？",
    "answer": "包括新的編碼器（BiCodec）、語音控制系統和標準數據集VoxBox。",
    "filename": "Spark_TTS"
  },
  {
    "question": "什麼是影響Spark-TTS中說話人相似度的原因？",
    "answer": "AR語言模型造成的說話人變異性影響了相似度。",
    "filename": "Spark_TTS"
  },
  {
    "question": "什麼是語音代碼化技術在Spark-TTS中的一個挑戰？",
    "answer": "二元碼元的解耦不充分，限制聲紋控制能力。",
    "filename": "Spark_TTS"
  },
  {
    "question": "VoxBox為何適合作為可控TTS的基準？",
    "answer": "數據源開源且包含完整的屬性標註，適合研究與比較。",
    "filename": "Spark_TTS"
  },
  {
    "question": "SparkVox主要用於什麼類型的任務？",
    "answer": "開放語音框架，用於語音合成、語音編碼及理解任務。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS的融合框架如何提升語音創建的靈活性？",
    "answer": "保持與傳統文本大語言模型對齊的單一編碼器架構。",
    "filename": "Spark_TTS"
  },
  {
    "question": "什麼是BiCodec相比其他編碼器的優勢？",
    "answer": "在低位元速率下提供更高的重建質量和語義對準。",
    "filename": "Spark_TTS"
  },
  {
    "question": "如何定義VoxBox中的性別和年齡分類準則？",
    "answer": "通過針對不同數據集的模型預測，使用明確準則進行分類。",
    "filename": "Spark_TTS"
  },
  {
    "question": "什麼是可以影響Spark-TTS性能的未來方向？",
    "answer": "加入更多的充權機制和改善音高調制進一步提高性能。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS在控制聲音屬性方面具備什麼特點？",
    "answer": "具備性別、音高、講話速率等粗粒度和細粒度控制。",
    "filename": "Spark_TTS"
  },
  {
    "question": "如何在BiCodec中實現全球語音特色的量化？",
    "answer": "使用FSQ對時不變的全局信息進行量化。",
    "filename": "Spark_TTS"
  },
  {
    "question": "哪些數據集被用來訓練Spark-TTS？",
    "answer": "來自29個開源數據集，包括AISHELL-3、EMNS、Librispeech等。",
    "filename": "Spark_TTS"
  },
  {
    "question": "使用Spark-TTS進行零樣本語音合成的策略有哪些？",
    "answer": "可以使用文本以及參考音頻來生成全局與語義碼元。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS有哪些標準化的性能評估指標？",
    "answer": "STOI、PESQ、SIM和UTMOS。",
    "filename": "Spark_TTS"
  },
  {
    "question": "BiCodec在語義碼元的重建中採用了什麼技術？",
    "answer": "Wave2vec 2.0的特徵用於語義碼元的抽取。",
    "filename": "Spark_TTS"
  },
  {
    "question": "在VoxBox數據集中有哪些語言和屬性標註？",
    "answer": "包括性別、音高、講話速率等多種屬性語言標註。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS的主要競爭優勢是什麼？",
    "answer": "它在合成速度和語音自然度上達到領先水平。",
    "filename": "Spark_TTS"
  },
  {
    "question": "BiCodec在語音合成的語音品質上如何評價？",
    "answer": "在低位元速率下提供出色的音質評價。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Spark-TTS在什麼指標上展示了優於Llasa的性能？",
    "answer": "雖然參數較少但在語音的智能和細節上超越Llasa。",
    "filename": "Spark_TTS"
  },
  {
    "question": "Physical AI系統的主要設計目的是什麼？",
    "answer": "與物理世界互動",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "Cosmos-Reason1模型可以透過什麼過程生成嵌入式決策？",
    "answer": "長鏈思維推理過程",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "階層本體論用來代表什麼知識？",
    "answer": "空間、時間和物理學的基本知識",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "Cosmos-Reason1-8B和Cosmos-Reason1-56B的差別在哪裡？",
    "answer": "模態和尺寸",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "模型在設計上使用了哪種架構來處理多模態嵌入？",
    "answer": "解碼器架構",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "物理AI模型必須具備哪些兩類推理能力？",
    "answer": "物理常識推理和嵌入式推理",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "嵌入式推理需要處理什麼樣的輸入資訊？",
    "answer": "複雜的感官輸入",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "如何定義物理常識中的時間類別？",
    "answer": "涵蓋動作、順序、因果關係、相機和規劃",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "物理AI模型應如何學習從互動中？",
    "answer": "透過動作和環境的反饋",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "嵌入式推理需要遵循什麼樣的限制？",
    "answer": "物理限制，例如慣性、摩擦和材料特性",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "Cosmos-Reason1使用的視覺編碼器為何？",
    "answer": "InternViT-300M-V2.5",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "MCQ生成過程中的第一步是什麼？",
    "answer": "基於人類偏好策劃影片",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "在嵌入式推理中，如何驗證動作完成情況？",
    "answer": "透過對任務完成情況的驗證",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "物理AI強化學習使用了什麼獎勵機制？",
    "answer": "規則為基礎的可驗證獎勵",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "如何透過嵌入式推理來預測動作效果？",
    "answer": "預測出因果關係",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "面向時間箭頭推理的資料集包含什麼？",
    "answer": "30,000條短影片及其反向版本",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "物理AI的強化學習後訓練在什麼型別資料集上生成問題？",
    "answer": "例如空間拼圖和時間箭頭的二元問題",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "嵌入式推理中有哪些具體環境，例如自主車輛中可能的問題？",
    "answer": "預測下一個最可能的動作",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "模型如何區分箭頭時間的正向和反向？",
    "answer": "透過訓練讓機器學習正向和反向的視覺線索",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "可選用於驗證直觀物理學的自監督方法有哪三個？",
    "answer": "空間拼圖、時間箭頭和物件恆常性",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "Cosmos-Reason1-56B在某些推理基準上優於哪些其他模型？",
    "answer": "些基準上的GPT-4o和OpenAI o1",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "模型如何利用Ego－車輛的行為預測他們的行動？",
    "answer": "基於影片內容的Ego－車輛預測",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "在設計學習過程中，物理AI SFT和RL分別帶來了哪些方面的改進？",
    "answer": "SFT提升了模型準確性超過10%，而RL進一步提高了8%",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "如何製作MCQ準備教材？",
    "answer": "使用了簡單、規則為基礎的設計",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "嵌入式推理需要能夠預測未來行動的哪類情報？",
    "answer": "最有可能的下一步行動",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "Cosmos-Reason1支援哪些不同型別的嵌入式代理？",
    "answer": "人類、動物、機器人系統等",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "下列哪個步驟是多模態大型語言模型的訓練步驟之一？",
    "answer": "視覺預訓練",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "下列哪類屬於物理常識的基礎類別？",
    "answer": "時間",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "物理AI領域中的隨機樣本批次的具體數量是什麼？",
    "answer": "128問批次",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "為什麼物理AI需要遵循實際的物理限制？",
    "answer": "為確保執行的穩定性、效率和安全性",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "機器如何從互動中學習在物理AI環境中適應？",
    "answer": "透過不斷更新其對環境的理解",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "如何透過嵌入式推理來確保行動承擔對理的影響？",
    "answer": "考慮因果關係",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "Cosmos-Reason1如何使用影片資訊生成反應？",
    "answer": "投影到LLM的token嵌入空間",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "嵌入式推理需要能預測動作的哪個效果？",
    "answer": "物理後果",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "轉化為MCQ的範例需要滿足什麼要求？",
    "answer": "簡單的字串匹配",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "考慮在製作影片遊戲時需要的計畫推理類別包括哪些？",
    "answer": "下一個可操作的任務",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "嵌入式推理需要能處理哪些型別的約束條件？",
    "answer": "真實世界的物理",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "Cosmos-Reason1模型在實體設計上包含的主要子模組是什麼？",
    "answer": "自注意力層和MLP層",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "Cosmos-Reason1按什麼方式融合資料，生成適應性強的影片反應？",
    "answer": "影片資訊整合到LLM",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "在MCQ為基礎的RL中，如何進行簡單的驗證？",
    "answer": "透過字串匹配",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "車輛系統中，如何檢測實際上下一步的行動？",
    "answer": "從多重可用選擇中進行動作預測",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "Cosmos-Reason1的嵌入式推理中需要涉及到的序列資訊是什麼？",
    "answer": "推理和情報更新序列",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "傳送影片片段中每幅448×448的幀有多少視覺token？",
    "answer": "1024個視覺token",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "人工註釋的物理常識二元及多項選擇問題共計多少個？",
    "answer": "5133個",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "物理AI系統需要遵循哪兩種思維系統？",
    "answer": "系統1和系統2",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "強化學習中，格式獎勵是如何激勵模型的？",
    "answer": "透過正規表示式匹配實現",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "哪些任務中需要以自監督形式生成資料？",
    "answer": "物理直覺任務",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "Cosmos-Reason1實驗架構中每次RL迭代是如何定義的？",
    "answer": "使用dataloader預處理文字和視覺資料",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "下列哪個是物理AI推理主要階段之一？",
    "answer": "一般監督微調（SFT）",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "常識推理的三大基本類別是什麼？",
    "answer": "空間、時間、基礎物理",
    "filename": "Cosmos-Reason1"
  },
  {
    "question": "什麼型號的電動輔助自行車本手冊適用於？",
    "answer": "Giant/Liv/Momentum",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "在開始騎乘前應該在哪裡閱讀額外的資訊？",
    "answer": "網站的支援部分和自行車使用手冊中的一般資訊",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "不遵守安全指示可能帶來什麼後果？",
    "answer": "可能造成死亡、嚴重人身傷害和/或嚴重財物損失",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "為什麼不應將電池和充電器接近水？",
    "answer": "因為可能會對電池和充電器造成損害",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼情況下需要立即中斷充電器和電池連接？",
    "answer": "一旦發現異味或冒煙",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何避免由於電池著火造成的危害？",
    "answer": "使用大量的沙覆蓋滅火，不要用水滅火",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼溫度範圍適合使用EnergyPak？",
    "answer": "-20°C 至 60°C",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "首次使用EnergyPak需要做什麼？",
    "answer": "建議完整充電",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "在哪種狀況下需要關閉EnergyPak的電源才能拆卸？",
    "answer": "在拆卸前",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼是智慧型充電器 4A, 48V, Dual 的特點？",
    "answer": "可監控電池狀態並調整充電過程，以提升速度和延長壽命",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "LED 紅色和綠色交替閃爍表示什麼狀態？",
    "answer": "充電問題",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "充電EnergyPak時應該保持自行車的什麼姿勢？",
    "answer": "平穩直立放置",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何判斷EnergyPak 智慧型側拉式電量已滿？",
    "answer": "指示燈顯示",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何開始為EnergyPak帶電池充電？",
    "answer": "將充電器連接到充電埠並插入插座",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "RideControl Ergo 的電源開關怎麼操作？",
    "answer": "按下至少1.5秒後放開",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "RideControl Ergo上的步行輔助怎麼使用？",
    "answer": "首先按步行輔助按鈕，再按輔助等級上按鈕",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼會導致SyncDrive 馬達的智慧型輔助調整功能啟動？",
    "answer": "按住輔助等級上或下按鈕2秒",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何為RideControl Dash修改顯示單位？",
    "answer": "按住資訊按鈕5秒",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼條件下外部裝置可以連接電動輔助自行車系統？",
    "answer": "符合連接器規格和電源規格",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "EnergyPak的儲存應有多少電量？",
    "answer": "約60%",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼方法不應用於清潔電動輔助自行車？",
    "answer": "高壓水管或空氣軟管",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "為什麼需要檢查鏈條張力？",
    "answer": "檢查鏈條鬆弛程度，避免損壞",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何處理損壞的舊電池？",
    "answer": "不得作為生活垃圾，應作為危險廢物處理",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "哪些自行車元件正常磨損不包括在保修範圍內？",
    "answer": "輪胎、鏈條、制動器、電纜和齒輪",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼樣的改裝可能會使保固失效？",
    "answer": "改裝原始設備或其他影響設計和操作的改動",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何安裝Shimano STI Lever？",
    "answer": "可以透過RideControl應用程式進行設定",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼是Sram AXS Bonus Button的功能？",
    "answer": "切換輔助等級和啟動智慧型輔助",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "為什麼運送前應取下可拆卸的電子元件？",
    "answer": "為避免運輸損傷",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼是EnergyPak的存放溫度範圍？",
    "answer": "-20°C 到 50°C",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何處理快要過期的EnergyPak電量？",
    "answer": "充電到60%",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何調整RideControl Dash的螢幕亮度？",
    "answer": "按燈光按鈕",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "在什麼情況下無法關閉S-Pedelecs的燈光？",
    "answer": "快速電動輔助自行車（S-Pedelecs）",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何在RideControl Dash上啟用智慧型輔助？",
    "answer": "同時按下輔助等級上和下按鈕2秒",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "為什麼攜帶鑰匙很重要？",
    "answer": "驗證和維護所需",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼原因會導致EnergyPak電量下降？",
    "answer": "不當存放或長期未使用",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "雨、雪、鹽對電動輔助自行車有什麼影響？",
    "answer": "可能導致腐蝕或損壞",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何正確存放EnergyPak？",
    "answer": "在乾燥安全的地方，以適當溫度存放",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼標準的混合動力自行車滿足25km/h支援？",
    "answer": "歐盟機械指令2006/42/EC",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何識別RideDash EVO的狀態列圖示？",
    "answer": "無線、燈光、通知和維修圖示",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼會影響騎乘里程？",
    "answer": "天氣、道路條件和使用方式",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何清潔電動輔助自行車？",
    "answer": "用軟布或刷子和中性清潔劑輕輕擦拭",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "為什麼避免在潮濕中使用USB-C口？",
    "answer": "防止液體進入造成損壞",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "如何啟用RideControl Ergo的步行輔助功能？",
    "answer": "按下步行輔助按鈕，接著按輔助等級上",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼時候需要使用快速充電器3A/4A, 36V？",
    "answer": "當需要快速充電而無電池或已充滿",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "LED紅色閃爍時表示什麼狀況？",
    "answer": "系統事件或故障指示",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼情況下會讓RideControl顯示器起霧？",
    "answer": "溫度快速變化引起",
    "filename": "E-bikeUsermanualV100"
  },
  {
    "question": "什麼是AIR模型的主要功能？",
    "answer": "快速場景理解。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR模型如何進行推理？",
    "answer": "使用遞歸神經網絡進行物件的迭代推理。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR的訓練過程有使用到什麼樣的數據集？",
    "answer": "使用多個MNIST數字圖像。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR模型如何從未標記的數據中學習？",
    "answer": "透過生成模型進行無監督學習。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "使用AIR進行推理時需要什麼樣的網絡架構？",
    "answer": "遞歸神經網絡。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR模型在3D場景中能解決什麼問題？",
    "answer": "物件計數、識別及姿勢推理。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "DAIR在什麼方面比AIR更優越？",
    "answer": "在推廣能力和插值任務上。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "DAIR模型如何實現更強的泛化能力？",
    "answer": "使用不同的推理網絡結構。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "什麼是モード自由能？",
    "answer": "模型在推理過程中用來評估數據的變分下界。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "DAIR與DRAW在泛化任務中有何比較？",
    "answer": "DAIR表現優於DRAW。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR模型的推理效能如何測量？",
    "answer": "通過每個推理步驟所需的時間來測量。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "什麼是普通異名變的再參數化技巧？",
    "answer": "在梯度估計中使用的技巧，用於處理連續型變量。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR模型如何實現快速推理？",
    "answer": "使用迭代的遞歸神經網絡和變分推理。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "在什麼情況下，AIR的推理效率比傳統方法高？",
    "answer": "在3D渲染器的應用中。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "什麼是推理的主要挑戰？",
    "answer": "處理複雜場景和多物件的推理。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "3D場景中使用AIR推理的好處是什麼？",
    "answer": "快速且準確的物件識別和姿勢還原。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "如何評估AIR模型的推理結果？",
    "answer": "通過與監督方法的比較進行評估。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "推理網絡通常對什麼進行建模？",
    "answer": "隱變量的抽樣分布參數。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "如何控制AIR推理網絡的停止條件？",
    "answer": "通過z_pres變量來實現。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "哪些實驗展示了AIR在不同場景中的表現？",
    "answer": "MNIST、Omniglot和Sprites實驗。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR如何處理變量攝像機的3D場景？",
    "answer": "增加隨機攝影機角度變量來進行推理。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "為什麼AIR能在少量標籤數據下表現出高精度？",
    "answer": "因為具有結構化的解釋能力。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "什麼是通過渲染器進行梯度估計的挑戰？",
    "answer": "通常不支持從渲染器反向獲取梯度。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "在何種情況下，直接優化似然的效果不如AIR好？",
    "answer": "可見地獲得不穩定的且對局部最小值更敏感。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "sprites實驗中使用的數據集是什麼樣的？",
    "answer": "包含紅色圓形、綠色方形和藍色菱形的50x50數據集。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "在Omniglot數據集的實驗中，AIR如何表現？",
    "answer": "成功學習空間上連貫的類似筆劃的元素。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "在數據驅動的推理方法中，如何實現快速預測？",
    "answer": "結合生成模型和神經網絡進行加速推理。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "什麼是可調的生成模型的挑戰？",
    "answer": "如何在不犧牲模型表現力的情況下進行复杂場景的推理。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "為什麼說統計基掣方式難以應用？",
    "answer": "因為統計基掣方式引發的誤差在像素處被均勻化。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "在什麼情況下，3D場景的相機位置影響推理的準確度？",
    "answer": "隨機選擇相機位置時。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "如何選擇使用圖像的哪一部分進行推理？",
    "answer": "通過學到的空間政策來選擇。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "什麼是字符或圖像的協方差矩陣？",
    "answer": "衡量字符或圖像等數據集維度的變化。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "與其他模型類型相比，VAE如何可以增加場景推理的靈活性？",
    "answer": "通過允許復雜場景的變量大小和變化。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "在推理過程中，如何避免模型解釋重複的物件？",
    "answer": "通過使用依賴於先前解釋的隱變量和影像。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR方法的填充高階結構模型的優勢是什麼？",
    "answer": "優化生成模型的準確性，改善泛化能力。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "超參數優化如何影響AIR的性能？",
    "answer": "影響網絡的一般化性能和結構化解釋的表現。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "為什麼DAIR可以具備更好的數據泛化性能？",
    "answer": "因為使用混合和不同的推理網絡架構。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "在Omniglot實驗中，隱藏原因是如何被識別的？",
    "answer": "通過學習不同數量的步驟來描述不同的字符複雜性。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR和DAIR如何與現有模型進行對比試驗？",
    "answer": "與DRAW、CNN、CAE進行比較。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "在什麼情況下，監督的方法可能會對推理結果產生誤導？",
    "answer": "當有對象某方或當標籤導致對序進行任意排序時。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "渲染器高效推理需要滿足什麼條件？",
    "answer": "滿足需求以處理複雜場景和數據誤差。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "為什麼傳統方法難以推理多物件場景？",
    "answer": "因為難以處理輸入圖像的空間結構變化。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "如何在推理中解決經常發生網頁多樣性問題？",
    "answer": "通過使用生成模型生成不同場景。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "DAIR使用優化方法如何在性能上與AIR比較？",
    "answer": "有較低的變分下界，但推廣能力較強。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR如何通過特定推理策略來優化推理效率？",
    "answer": "通過學習適應場景複雜度的結構來執行推理。",
    "filename": "Fast_Scene_Understanding"
  },
  {
    "question": "AIR和DAIR的背後是什麼樣的一般性模型？",
    "answer": "可解釋生成模型和當前狀態下的遞歸推理模型。",
    "filename": "Fast_Scene_Understanding"
  }
]